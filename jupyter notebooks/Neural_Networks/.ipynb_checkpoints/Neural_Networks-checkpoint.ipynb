{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Networks\n",
    "\n",
    "Artificial intelligence \n",
    "\n",
    "1. NLP (Natural Language Processing),\n",
    "2. Computer vision (Faces, object recognition, ...),\n",
    "3. Uses: stock market, medical/health care. \n",
    "\n",
    "Three types: ResNet, LSTM, Convolution Neural Network CNN. \n",
    "\n",
    "## Real networks: how do they work?\n",
    "\n",
    "Parts: soma, dendrites (receive information), axons (carry information and sends to other neurons).\n",
    "Neurons work using electric signals. There are voltage variations. \n",
    "\n",
    "## Artificial neural networks\n",
    "\n",
    "Artificial neurons are able to receive information. Then the neuron perform a calculation and gives a result. \n",
    "This involves an activation function. \n",
    "\n",
    "<img src=\"neuron.png\" alt=\"Neuron\" width=\"500\" height=\"600\">\n",
    "\n",
    "The neuron use the weights $w_i$ to calculate $z = \\sum_{i=1}^{n}w_i x_i$, where $x_i$ is the input. \n",
    "Now we apply the activation function $\\sigma$ to $z$ getting this way that\n",
    "\n",
    "$$\\sigma(z) = \\sigma\\left( \\sum_{i=1}^{n}w_i x_i\\right),$$\n",
    "\n",
    "The model adjust the weights to the data set. There are different activations functions as the sigmoid, etc. \n",
    "We can also consider a function $\\sigma(z)$ which takes the value 1 when $z \\geq 0$ and the value $0$ when $z < 0$.\n",
    "There is another typical activation function ReLu where $\\sigma(z)$ is $z$ when $z > 0$ and $0$ otherwise. \n",
    "\n",
    "<img src=\"network.png\" alt=\"One layer Neural Network\" width=\"250\" height=\"300\">\n",
    "\n",
    "Here you can see a neural network with one layer and several neurons. We can have neural networks with several layers.\n",
    "\n",
    "## Binary classification using neural networks\n",
    "\n",
    "We want to know if an application, to certain university, will be accepted or not.\n",
    "\n",
    "<img src=\"application.png\" alt=\"Application matrix\" width=\"250\" height=\"300\">\n",
    "\n",
    "In this case we will use the logistic function $p = \\frac{1}{1+\\exp(-x \\cdot \\beta)}$. The output of this neural network is the probability of being accepted by certain university. If we use the logistic function this is equivalent to logistic regression.\n",
    "\n",
    "<img src=\"logistic.png\" alt=\"Application matrix\" width=\"250\" height=\"300\">\n",
    "\n",
    "In general we have an 'output layer' which is at the end of our neural network. Deep neural network are composed by a lot of layers.\n",
    "\n",
    "## Gradient descent\n",
    "\n",
    "<img src=\"deep.png\" alt=\"Application matrix\" width=\"250\" height=\"300\">\n",
    "\n",
    "Suppose we build a neural network with multiple layers and an output layer at the end. We can to solve a classification problem, then \n",
    "\n",
    "$$p = \\sigma(\\sum_{i=1}^{n}w_{i}^{n-1}\\sigma(\\dots)).$$\n",
    "\n",
    "We should compose the activation function several times, and evaluate in the proper values. Our likelihood function is\n",
    "$$L = \\prod_{i=1}^{N} p_i^{y_i}(1-p_i)^{1-y_i}.$$\n",
    "We want to maximize the likelihood function. To do this we use the log-likelihood function $l$.\n",
    "\n",
    "We want to do this in a computational way, therefore we need to introduce an algorithm in order to maximize this function. In this case we will use gradient descent. We want to minimize the error and maximize the likelihood function. Recall that the weights are not defined a priori, we need to adjust these weights to our data set.\n",
    "\n",
    "We have the cost function $C = -l$, we want to minimize $C$. If we minimize $C$ we are maximizing $l$ and therefore $L$.\n",
    "\n",
    "We want to find the weights which minimizes the $C$ function. \n",
    "\n",
    "<img src=\"Gradient.png\" alt=\"Application matrix\" width=\"250\" height=\"300\">\n",
    "\n",
    "We want to arrive to the minimum step by step (for that reason this is an algorithm). First we start in any point $w_1$, then we calculate the slope at that point. If the slope is positive we move to the left, if the slope is negative we move to the right (we choose other point using the tangent line, plane etc. This is similar to Newton-Raphson).  \n",
    "\n",
    "## Stochastic Gradient Descent \n",
    "\n",
    "We want to calculate the weights in our neural network. This is a dinamical process where we have several layers dependent on the previous ones.\n",
    "\n",
    "How to update the weights $w$?\n",
    "\n",
    "1. Update weights by using $\\nabla_{w}C$ of one data point\n",
    "2. Update weights by using the average of $\\sum_{i}\\nabla_{w}C_i$\n",
    "3. Update $w$ by taking the average of $\\sum_{i}\\nabla_{w}C_i/m$. Here we divide the weights into mini-batchs. \n",
    "   We adjust a particular group of weights, and then we switch to the next one etc. Here we use $N/m$ iterations      where $m$ is the number of weights on each mini-batchs (we divide the weights into groups)\n",
    "\n",
    "## Backpropagation \n",
    "\n",
    "How do we calculate the gradient of the cost function against all the weights in our neural network?\n",
    "\n",
    "To calculate the partial derivatives of each $z_k^{l} = \\sum_{j=1}^{n}w_{kj}^{l-1}a_j^{l-1}$, we need to use the chain rule. If we write a function $f(z_1^{l}, \\dots, z_n^{l})$, then we need to use the chain rule to calculate the partial derivatives. Notice that the cost function depends on these $z$ variables, therefore we should follow the same approach than with $f$.\n",
    "\n",
    "This is called back propagration becasue the k,l partial derivative depends on the l+1,m partial derivative. Therefore we get the previous partial derivative from the next partial derivative.\n",
    "\n",
    "We have\n",
    "\n",
    "$$\\frac{\\partial C}{\\partial z_k^{l}} = \\sum_{m} \\frac{\\partial C}{\\partial_{m}^{l+1}}w_{mk}^{l}\\sigma'(z_k^{l}).$$\n",
    "\n",
    "For the mathematical details read Pattern Recognition and Machine Learning from C. Bishop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing NN for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logData = pd.read_csv(\"logistic_regression_optimization.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = logData.iloc[:,0:-1].values\n",
    "y = logData.iloc[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[3.83389295, 1.1991905 , 4.52605611]]), array([-4.92802048])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/victormaciamedina/Library/Python/3.8/lib/python/site-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(penalty ='none', solver = 'lbfgs').fit(x,y) # build a logistic regression model\n",
    "print([clf.coef_, clf.intercept_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression with a single neuron\n",
    "\n",
    "## Theoretical part.\n",
    "\n",
    "$$p = a = \\frac{1}{1+\\exp{-(w_0+w_1x_1+w_2x_2+w_3x_3)}}$$\n",
    "\n",
    "Loss function: binary_crossentropy which is\n",
    "\n",
    "$$L = - \\sum_{i=1}^{N} (y^{i}log(a^ i)+(1-y^{i})log(1-a^{i}))$$\n",
    "\n",
    "which is equivalent to the geometric likelihood function except for a negative sign. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential() # start a sequential neuron\n",
    "model.add(layers.Dense(1, input_shape = (3,), use_bias = True, activation = 'sigmoid'))\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(0.01), loss = 'binary_crossentropy', metrics = ['accuracy']) \n",
    "\n",
    "# define loss and optimization methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-1.0499663 ],\n",
       "        [ 0.7679441 ],\n",
       "        [-0.84475136]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights() # initial weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6830759930391261"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testinput = np.array([0,1,0])\n",
    "1/(1+np.exp(-np.dot(model.get_weights()[0].reshape(-1),testinput)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.68307596]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(model(np.array([[0,1,0]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.2108 - accuracy: 0.5322 - val_loss: 0.7030 - val_accuracy: 0.6270\n",
      "Epoch 2/200\n",
      "80/80 [==============================] - 0s 636us/step - loss: 0.5105 - accuracy: 0.7527 - val_loss: 0.3654 - val_accuracy: 0.8710\n",
      "Epoch 3/200\n",
      "80/80 [==============================] - 0s 673us/step - loss: 0.3171 - accuracy: 0.9028 - val_loss: 0.2648 - val_accuracy: 0.9330\n",
      "Epoch 4/200\n",
      "80/80 [==============================] - 0s 696us/step - loss: 0.2506 - accuracy: 0.9402 - val_loss: 0.2192 - val_accuracy: 0.9510\n",
      "Epoch 5/200\n",
      "80/80 [==============================] - 0s 662us/step - loss: 0.2164 - accuracy: 0.9445 - val_loss: 0.1938 - val_accuracy: 0.9620\n",
      "Epoch 6/200\n",
      "80/80 [==============================] - 0s 670us/step - loss: 0.1950 - accuracy: 0.9467 - val_loss: 0.1761 - val_accuracy: 0.9650\n",
      "Epoch 7/200\n",
      "80/80 [==============================] - 0s 653us/step - loss: 0.1803 - accuracy: 0.9485 - val_loss: 0.1616 - val_accuracy: 0.9620\n",
      "Epoch 8/200\n",
      "80/80 [==============================] - 0s 664us/step - loss: 0.1691 - accuracy: 0.9480 - val_loss: 0.1518 - val_accuracy: 0.9640\n",
      "Epoch 9/200\n",
      "80/80 [==============================] - 0s 657us/step - loss: 0.1608 - accuracy: 0.9490 - val_loss: 0.1439 - val_accuracy: 0.9640\n",
      "Epoch 10/200\n",
      "80/80 [==============================] - 0s 727us/step - loss: 0.1539 - accuracy: 0.9488 - val_loss: 0.1386 - val_accuracy: 0.9690\n",
      "Epoch 11/200\n",
      "80/80 [==============================] - 0s 644us/step - loss: 0.1487 - accuracy: 0.9507 - val_loss: 0.1326 - val_accuracy: 0.9650\n",
      "Epoch 12/200\n",
      "80/80 [==============================] - 0s 653us/step - loss: 0.1441 - accuracy: 0.9505 - val_loss: 0.1275 - val_accuracy: 0.9650\n",
      "Epoch 13/200\n",
      "80/80 [==============================] - 0s 649us/step - loss: 0.1405 - accuracy: 0.9505 - val_loss: 0.1237 - val_accuracy: 0.9640\n",
      "Epoch 14/200\n",
      "80/80 [==============================] - 0s 694us/step - loss: 0.1372 - accuracy: 0.9495 - val_loss: 0.1202 - val_accuracy: 0.9630\n",
      "Epoch 15/200\n",
      "80/80 [==============================] - 0s 693us/step - loss: 0.1342 - accuracy: 0.9498 - val_loss: 0.1179 - val_accuracy: 0.9650\n",
      "Epoch 16/200\n",
      "80/80 [==============================] - 0s 614us/step - loss: 0.1318 - accuracy: 0.9492 - val_loss: 0.1163 - val_accuracy: 0.9670\n",
      "Epoch 17/200\n",
      "80/80 [==============================] - 0s 613us/step - loss: 0.1298 - accuracy: 0.9490 - val_loss: 0.1130 - val_accuracy: 0.9670\n",
      "Epoch 18/200\n",
      "80/80 [==============================] - 0s 622us/step - loss: 0.1284 - accuracy: 0.9482 - val_loss: 0.1107 - val_accuracy: 0.9660\n",
      "Epoch 19/200\n",
      "80/80 [==============================] - 0s 611us/step - loss: 0.1266 - accuracy: 0.9492 - val_loss: 0.1090 - val_accuracy: 0.9650\n",
      "Epoch 20/200\n",
      "80/80 [==============================] - 0s 709us/step - loss: 0.1253 - accuracy: 0.9495 - val_loss: 0.1077 - val_accuracy: 0.9670\n",
      "Epoch 21/200\n",
      "80/80 [==============================] - 0s 613us/step - loss: 0.1240 - accuracy: 0.9505 - val_loss: 0.1059 - val_accuracy: 0.9670\n",
      "Epoch 22/200\n",
      "80/80 [==============================] - 0s 619us/step - loss: 0.1224 - accuracy: 0.9482 - val_loss: 0.1071 - val_accuracy: 0.9650\n",
      "Epoch 23/200\n",
      "80/80 [==============================] - 0s 600us/step - loss: 0.1215 - accuracy: 0.9503 - val_loss: 0.1033 - val_accuracy: 0.9650\n",
      "Epoch 24/200\n",
      "80/80 [==============================] - 0s 611us/step - loss: 0.1210 - accuracy: 0.9490 - val_loss: 0.1025 - val_accuracy: 0.9660\n",
      "Epoch 25/200\n",
      "80/80 [==============================] - 0s 708us/step - loss: 0.1200 - accuracy: 0.9492 - val_loss: 0.1026 - val_accuracy: 0.9650\n",
      "Epoch 26/200\n",
      "80/80 [==============================] - 0s 649us/step - loss: 0.1197 - accuracy: 0.9475 - val_loss: 0.1004 - val_accuracy: 0.9670\n",
      "Epoch 27/200\n",
      "80/80 [==============================] - 0s 635us/step - loss: 0.1188 - accuracy: 0.9500 - val_loss: 0.0997 - val_accuracy: 0.9670\n",
      "Epoch 28/200\n",
      "80/80 [==============================] - 0s 660us/step - loss: 0.1183 - accuracy: 0.9490 - val_loss: 0.0990 - val_accuracy: 0.9660\n",
      "Epoch 29/200\n",
      "80/80 [==============================] - 0s 694us/step - loss: 0.1177 - accuracy: 0.9488 - val_loss: 0.0996 - val_accuracy: 0.9650\n",
      "Epoch 30/200\n",
      "80/80 [==============================] - 0s 669us/step - loss: 0.1173 - accuracy: 0.9507 - val_loss: 0.0976 - val_accuracy: 0.9670\n",
      "Epoch 31/200\n",
      "80/80 [==============================] - 0s 659us/step - loss: 0.1169 - accuracy: 0.9500 - val_loss: 0.0981 - val_accuracy: 0.9660\n",
      "Epoch 32/200\n",
      "80/80 [==============================] - 0s 636us/step - loss: 0.1165 - accuracy: 0.9500 - val_loss: 0.0979 - val_accuracy: 0.9660\n",
      "Epoch 33/200\n",
      "80/80 [==============================] - 0s 611us/step - loss: 0.1163 - accuracy: 0.9500 - val_loss: 0.0961 - val_accuracy: 0.9680\n",
      "Epoch 34/200\n",
      "80/80 [==============================] - 0s 611us/step - loss: 0.1161 - accuracy: 0.9488 - val_loss: 0.0958 - val_accuracy: 0.9680\n",
      "Epoch 35/200\n",
      "80/80 [==============================] - 0s 616us/step - loss: 0.1156 - accuracy: 0.9490 - val_loss: 0.0954 - val_accuracy: 0.9680\n",
      "Epoch 36/200\n",
      "80/80 [==============================] - 0s 629us/step - loss: 0.1152 - accuracy: 0.9495 - val_loss: 0.0946 - val_accuracy: 0.9670\n",
      "Epoch 37/200\n",
      "80/80 [==============================] - 0s 613us/step - loss: 0.1149 - accuracy: 0.9485 - val_loss: 0.0966 - val_accuracy: 0.9660\n",
      "Epoch 38/200\n",
      "80/80 [==============================] - 0s 630us/step - loss: 0.1155 - accuracy: 0.9498 - val_loss: 0.0943 - val_accuracy: 0.9680\n",
      "Epoch 39/200\n",
      "80/80 [==============================] - 0s 636us/step - loss: 0.1148 - accuracy: 0.9488 - val_loss: 0.0939 - val_accuracy: 0.9680\n",
      "Epoch 40/200\n",
      "80/80 [==============================] - 0s 660us/step - loss: 0.1149 - accuracy: 0.9488 - val_loss: 0.0937 - val_accuracy: 0.9670\n",
      "Epoch 41/200\n",
      "80/80 [==============================] - 0s 635us/step - loss: 0.1141 - accuracy: 0.9495 - val_loss: 0.0932 - val_accuracy: 0.9660\n",
      "Epoch 42/200\n",
      "80/80 [==============================] - 0s 630us/step - loss: 0.1144 - accuracy: 0.9480 - val_loss: 0.0936 - val_accuracy: 0.9670\n",
      "Epoch 43/200\n",
      "80/80 [==============================] - 0s 621us/step - loss: 0.1141 - accuracy: 0.9495 - val_loss: 0.0932 - val_accuracy: 0.9680\n",
      "Epoch 44/200\n",
      "80/80 [==============================] - 0s 635us/step - loss: 0.1141 - accuracy: 0.9505 - val_loss: 0.0924 - val_accuracy: 0.9670\n",
      "Epoch 45/200\n",
      "80/80 [==============================] - 0s 708us/step - loss: 0.1139 - accuracy: 0.9490 - val_loss: 0.0924 - val_accuracy: 0.9670\n",
      "Epoch 46/200\n",
      "80/80 [==============================] - 0s 633us/step - loss: 0.1139 - accuracy: 0.9503 - val_loss: 0.0923 - val_accuracy: 0.9670\n",
      "Epoch 47/200\n",
      "80/80 [==============================] - 0s 613us/step - loss: 0.1136 - accuracy: 0.9500 - val_loss: 0.0922 - val_accuracy: 0.9670\n",
      "Epoch 48/200\n",
      "80/80 [==============================] - 0s 599us/step - loss: 0.1135 - accuracy: 0.9492 - val_loss: 0.0921 - val_accuracy: 0.9670\n",
      "Epoch 49/200\n",
      "80/80 [==============================] - 0s 618us/step - loss: 0.1135 - accuracy: 0.9492 - val_loss: 0.0918 - val_accuracy: 0.9660\n",
      "Epoch 50/200\n",
      "80/80 [==============================] - 0s 655us/step - loss: 0.1137 - accuracy: 0.9500 - val_loss: 0.0921 - val_accuracy: 0.9660\n",
      "Epoch 51/200\n",
      "80/80 [==============================] - 0s 636us/step - loss: 0.1133 - accuracy: 0.9495 - val_loss: 0.0914 - val_accuracy: 0.9670\n",
      "Epoch 52/200\n",
      "80/80 [==============================] - 0s 638us/step - loss: 0.1134 - accuracy: 0.9503 - val_loss: 0.0912 - val_accuracy: 0.9660\n",
      "Epoch 53/200\n",
      "80/80 [==============================] - 0s 636us/step - loss: 0.1133 - accuracy: 0.9492 - val_loss: 0.0917 - val_accuracy: 0.9660\n",
      "Epoch 54/200\n",
      "80/80 [==============================] - 0s 881us/step - loss: 0.1133 - accuracy: 0.9490 - val_loss: 0.0913 - val_accuracy: 0.9680\n",
      "Epoch 55/200\n",
      "80/80 [==============================] - 0s 751us/step - loss: 0.1137 - accuracy: 0.9495 - val_loss: 0.0911 - val_accuracy: 0.9670\n",
      "Epoch 56/200\n",
      "80/80 [==============================] - 0s 778us/step - loss: 0.1132 - accuracy: 0.9500 - val_loss: 0.0910 - val_accuracy: 0.9670\n",
      "Epoch 57/200\n",
      "80/80 [==============================] - 0s 611us/step - loss: 0.1132 - accuracy: 0.9490 - val_loss: 0.0914 - val_accuracy: 0.9670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "80/80 [==============================] - 0s 692us/step - loss: 0.1132 - accuracy: 0.9490 - val_loss: 0.0908 - val_accuracy: 0.9680\n",
      "Epoch 59/200\n",
      "80/80 [==============================] - 0s 714us/step - loss: 0.1133 - accuracy: 0.9498 - val_loss: 0.0911 - val_accuracy: 0.9660\n",
      "Epoch 60/200\n",
      "80/80 [==============================] - 0s 647us/step - loss: 0.1133 - accuracy: 0.9500 - val_loss: 0.0916 - val_accuracy: 0.9660\n",
      "Epoch 61/200\n",
      "80/80 [==============================] - 0s 627us/step - loss: 0.1131 - accuracy: 0.9503 - val_loss: 0.0906 - val_accuracy: 0.9670\n",
      "Epoch 62/200\n",
      "80/80 [==============================] - 0s 624us/step - loss: 0.1129 - accuracy: 0.9490 - val_loss: 0.0912 - val_accuracy: 0.9660\n",
      "Epoch 63/200\n",
      "80/80 [==============================] - 0s 786us/step - loss: 0.1134 - accuracy: 0.9492 - val_loss: 0.0909 - val_accuracy: 0.9660\n",
      "Epoch 64/200\n",
      "80/80 [==============================] - 0s 780us/step - loss: 0.1131 - accuracy: 0.9488 - val_loss: 0.0904 - val_accuracy: 0.9670\n",
      "Epoch 65/200\n",
      "80/80 [==============================] - 0s 642us/step - loss: 0.1129 - accuracy: 0.9515 - val_loss: 0.0902 - val_accuracy: 0.9670\n",
      "Epoch 66/200\n",
      "80/80 [==============================] - 0s 598us/step - loss: 0.1131 - accuracy: 0.9500 - val_loss: 0.0912 - val_accuracy: 0.9650\n",
      "Epoch 67/200\n",
      "80/80 [==============================] - 0s 596us/step - loss: 0.1135 - accuracy: 0.9495 - val_loss: 0.0901 - val_accuracy: 0.9670\n",
      "Epoch 68/200\n",
      "80/80 [==============================] - 0s 609us/step - loss: 0.1131 - accuracy: 0.9492 - val_loss: 0.0901 - val_accuracy: 0.9660\n",
      "Epoch 69/200\n",
      "80/80 [==============================] - 0s 617us/step - loss: 0.1130 - accuracy: 0.9490 - val_loss: 0.0900 - val_accuracy: 0.9670\n",
      "Epoch 70/200\n",
      "80/80 [==============================] - 0s 708us/step - loss: 0.1130 - accuracy: 0.9492 - val_loss: 0.0904 - val_accuracy: 0.9660\n",
      "Epoch 71/200\n",
      "80/80 [==============================] - 0s 665us/step - loss: 0.1131 - accuracy: 0.9495 - val_loss: 0.0906 - val_accuracy: 0.9650\n",
      "Epoch 72/200\n",
      "80/80 [==============================] - 0s 604us/step - loss: 0.1132 - accuracy: 0.9488 - val_loss: 0.0902 - val_accuracy: 0.9680\n",
      "Epoch 73/200\n",
      "80/80 [==============================] - 0s 606us/step - loss: 0.1133 - accuracy: 0.9503 - val_loss: 0.0901 - val_accuracy: 0.9680\n",
      "Epoch 74/200\n",
      "80/80 [==============================] - 0s 601us/step - loss: 0.1127 - accuracy: 0.9492 - val_loss: 0.0901 - val_accuracy: 0.9670\n",
      "Epoch 75/200\n",
      "80/80 [==============================] - 0s 599us/step - loss: 0.1129 - accuracy: 0.9492 - val_loss: 0.0899 - val_accuracy: 0.9670\n",
      "Epoch 76/200\n",
      "80/80 [==============================] - 0s 608us/step - loss: 0.1130 - accuracy: 0.9503 - val_loss: 0.0903 - val_accuracy: 0.9670\n",
      "Epoch 77/200\n",
      "80/80 [==============================] - 0s 601us/step - loss: 0.1132 - accuracy: 0.9517 - val_loss: 0.0897 - val_accuracy: 0.9670\n",
      "Epoch 78/200\n",
      "80/80 [==============================] - 0s 607us/step - loss: 0.1133 - accuracy: 0.9495 - val_loss: 0.0901 - val_accuracy: 0.9670\n",
      "Epoch 79/200\n",
      "80/80 [==============================] - 0s 647us/step - loss: 0.1128 - accuracy: 0.9492 - val_loss: 0.0899 - val_accuracy: 0.9680\n",
      "Epoch 80/200\n",
      "80/80 [==============================] - 0s 636us/step - loss: 0.1130 - accuracy: 0.9495 - val_loss: 0.0906 - val_accuracy: 0.9670\n",
      "Epoch 81/200\n",
      "80/80 [==============================] - 0s 628us/step - loss: 0.1128 - accuracy: 0.9498 - val_loss: 0.0898 - val_accuracy: 0.9670\n",
      "Epoch 82/200\n",
      "80/80 [==============================] - 0s 651us/step - loss: 0.1130 - accuracy: 0.9500 - val_loss: 0.0897 - val_accuracy: 0.9670\n",
      "Epoch 83/200\n",
      "80/80 [==============================] - 0s 636us/step - loss: 0.1129 - accuracy: 0.9500 - val_loss: 0.0900 - val_accuracy: 0.9670\n",
      "Epoch 84/200\n",
      "80/80 [==============================] - 0s 704us/step - loss: 0.1128 - accuracy: 0.9488 - val_loss: 0.0897 - val_accuracy: 0.9670\n",
      "Epoch 85/200\n",
      "80/80 [==============================] - 0s 662us/step - loss: 0.1128 - accuracy: 0.9495 - val_loss: 0.0905 - val_accuracy: 0.9650\n",
      "Epoch 86/200\n",
      "80/80 [==============================] - 0s 619us/step - loss: 0.1129 - accuracy: 0.9490 - val_loss: 0.0908 - val_accuracy: 0.9650\n",
      "Epoch 87/200\n",
      "80/80 [==============================] - 0s 613us/step - loss: 0.1130 - accuracy: 0.9505 - val_loss: 0.0896 - val_accuracy: 0.9670\n",
      "Epoch 88/200\n",
      "80/80 [==============================] - 0s 624us/step - loss: 0.1129 - accuracy: 0.9492 - val_loss: 0.0900 - val_accuracy: 0.9660\n",
      "Epoch 89/200\n",
      "80/80 [==============================] - 0s 700us/step - loss: 0.1130 - accuracy: 0.9495 - val_loss: 0.0894 - val_accuracy: 0.9670\n",
      "Epoch 90/200\n",
      "80/80 [==============================] - 0s 604us/step - loss: 0.1127 - accuracy: 0.9492 - val_loss: 0.0897 - val_accuracy: 0.9670\n",
      "Epoch 91/200\n",
      "80/80 [==============================] - 0s 629us/step - loss: 0.1131 - accuracy: 0.9485 - val_loss: 0.0902 - val_accuracy: 0.9670\n",
      "Epoch 92/200\n",
      "80/80 [==============================] - 0s 636us/step - loss: 0.1133 - accuracy: 0.9490 - val_loss: 0.0900 - val_accuracy: 0.9660\n",
      "Epoch 93/200\n",
      "80/80 [==============================] - 0s 614us/step - loss: 0.1127 - accuracy: 0.9482 - val_loss: 0.0903 - val_accuracy: 0.9660\n",
      "Epoch 94/200\n",
      "80/80 [==============================] - 0s 683us/step - loss: 0.1128 - accuracy: 0.9488 - val_loss: 0.0897 - val_accuracy: 0.9670\n",
      "Epoch 95/200\n",
      "80/80 [==============================] - 0s 625us/step - loss: 0.1129 - accuracy: 0.9503 - val_loss: 0.0897 - val_accuracy: 0.9680\n",
      "Epoch 96/200\n",
      "80/80 [==============================] - 0s 624us/step - loss: 0.1128 - accuracy: 0.9495 - val_loss: 0.0898 - val_accuracy: 0.9670\n",
      "Epoch 97/200\n",
      "80/80 [==============================] - 0s 662us/step - loss: 0.1127 - accuracy: 0.9492 - val_loss: 0.0904 - val_accuracy: 0.9660\n",
      "Epoch 98/200\n",
      "80/80 [==============================] - 0s 645us/step - loss: 0.1139 - accuracy: 0.9503 - val_loss: 0.0903 - val_accuracy: 0.9650\n",
      "Epoch 99/200\n",
      "80/80 [==============================] - 0s 713us/step - loss: 0.1131 - accuracy: 0.9492 - val_loss: 0.0899 - val_accuracy: 0.9680\n",
      "Epoch 100/200\n",
      "80/80 [==============================] - 0s 641us/step - loss: 0.1132 - accuracy: 0.9495 - val_loss: 0.0903 - val_accuracy: 0.9650\n",
      "Epoch 101/200\n",
      "80/80 [==============================] - 0s 625us/step - loss: 0.1128 - accuracy: 0.9492 - val_loss: 0.0902 - val_accuracy: 0.9660\n",
      "Epoch 102/200\n",
      "80/80 [==============================] - 0s 620us/step - loss: 0.1130 - accuracy: 0.9500 - val_loss: 0.0897 - val_accuracy: 0.9670\n",
      "Epoch 103/200\n",
      "80/80 [==============================] - 0s 643us/step - loss: 0.1130 - accuracy: 0.9498 - val_loss: 0.0894 - val_accuracy: 0.9680\n",
      "Epoch 104/200\n",
      "80/80 [==============================] - 0s 640us/step - loss: 0.1126 - accuracy: 0.9495 - val_loss: 0.0901 - val_accuracy: 0.9650\n",
      "Epoch 105/200\n",
      "80/80 [==============================] - 0s 601us/step - loss: 0.1132 - accuracy: 0.9498 - val_loss: 0.0900 - val_accuracy: 0.9650\n",
      "Epoch 106/200\n",
      "80/80 [==============================] - 0s 604us/step - loss: 0.1132 - accuracy: 0.9490 - val_loss: 0.0895 - val_accuracy: 0.9670\n",
      "Epoch 107/200\n",
      "80/80 [==============================] - 0s 622us/step - loss: 0.1133 - accuracy: 0.9492 - val_loss: 0.0895 - val_accuracy: 0.9680\n",
      "Epoch 108/200\n",
      "80/80 [==============================] - 0s 657us/step - loss: 0.1128 - accuracy: 0.9498 - val_loss: 0.0895 - val_accuracy: 0.9680\n",
      "Epoch 109/200\n",
      "80/80 [==============================] - 0s 632us/step - loss: 0.1131 - accuracy: 0.9500 - val_loss: 0.0894 - val_accuracy: 0.9660\n",
      "Epoch 110/200\n",
      "80/80 [==============================] - 0s 606us/step - loss: 0.1129 - accuracy: 0.9495 - val_loss: 0.0896 - val_accuracy: 0.9670\n",
      "Epoch 111/200\n",
      "80/80 [==============================] - 0s 603us/step - loss: 0.1128 - accuracy: 0.9503 - val_loss: 0.0893 - val_accuracy: 0.9680\n",
      "Epoch 112/200\n",
      "80/80 [==============================] - 0s 607us/step - loss: 0.1130 - accuracy: 0.9510 - val_loss: 0.0897 - val_accuracy: 0.9670\n",
      "Epoch 113/200\n",
      "80/80 [==============================] - 0s 621us/step - loss: 0.1131 - accuracy: 0.9492 - val_loss: 0.0894 - val_accuracy: 0.9670\n",
      "Epoch 114/200\n",
      "80/80 [==============================] - 0s 687us/step - loss: 0.1130 - accuracy: 0.9500 - val_loss: 0.0894 - val_accuracy: 0.9670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/200\n",
      "80/80 [==============================] - 0s 610us/step - loss: 0.1128 - accuracy: 0.9485 - val_loss: 0.0897 - val_accuracy: 0.9670\n",
      "Epoch 116/200\n",
      "80/80 [==============================] - 0s 606us/step - loss: 0.1131 - accuracy: 0.9503 - val_loss: 0.0895 - val_accuracy: 0.9660\n",
      "Epoch 117/200\n",
      "80/80 [==============================] - 0s 617us/step - loss: 0.1131 - accuracy: 0.9498 - val_loss: 0.0902 - val_accuracy: 0.9650\n",
      "Epoch 118/200\n",
      "80/80 [==============================] - 0s 620us/step - loss: 0.1129 - accuracy: 0.9498 - val_loss: 0.0893 - val_accuracy: 0.9670\n",
      "Epoch 119/200\n",
      "80/80 [==============================] - 0s 619us/step - loss: 0.1126 - accuracy: 0.9500 - val_loss: 0.0899 - val_accuracy: 0.9660\n",
      "Epoch 120/200\n",
      "80/80 [==============================] - 0s 603us/step - loss: 0.1129 - accuracy: 0.9477 - val_loss: 0.0893 - val_accuracy: 0.9670\n",
      "Epoch 121/200\n",
      "80/80 [==============================] - 0s 611us/step - loss: 0.1127 - accuracy: 0.9507 - val_loss: 0.0894 - val_accuracy: 0.9670\n",
      "Epoch 122/200\n",
      "80/80 [==============================] - 0s 624us/step - loss: 0.1128 - accuracy: 0.9488 - val_loss: 0.0900 - val_accuracy: 0.9660\n",
      "Epoch 123/200\n",
      "80/80 [==============================] - 0s 626us/step - loss: 0.1129 - accuracy: 0.9490 - val_loss: 0.0900 - val_accuracy: 0.9670\n",
      "Epoch 124/200\n",
      "80/80 [==============================] - 0s 623us/step - loss: 0.1127 - accuracy: 0.9492 - val_loss: 0.0907 - val_accuracy: 0.9660\n",
      "Epoch 125/200\n",
      "80/80 [==============================] - 0s 598us/step - loss: 0.1126 - accuracy: 0.9492 - val_loss: 0.0893 - val_accuracy: 0.9670\n",
      "Epoch 126/200\n",
      "80/80 [==============================] - 0s 626us/step - loss: 0.1131 - accuracy: 0.9495 - val_loss: 0.0895 - val_accuracy: 0.9660\n",
      "Epoch 127/200\n",
      "80/80 [==============================] - 0s 607us/step - loss: 0.1127 - accuracy: 0.9498 - val_loss: 0.0898 - val_accuracy: 0.9660\n",
      "Epoch 128/200\n",
      "80/80 [==============================] - 0s 635us/step - loss: 0.1130 - accuracy: 0.9492 - val_loss: 0.0901 - val_accuracy: 0.9650\n",
      "Epoch 129/200\n",
      "80/80 [==============================] - 0s 614us/step - loss: 0.1129 - accuracy: 0.9490 - val_loss: 0.0902 - val_accuracy: 0.9650\n",
      "Epoch 130/200\n",
      "80/80 [==============================] - 0s 674us/step - loss: 0.1133 - accuracy: 0.9490 - val_loss: 0.0896 - val_accuracy: 0.9670\n",
      "Epoch 131/200\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.1128 - accuracy: 0.9492 - val_loss: 0.0897 - val_accuracy: 0.9670\n",
      "Epoch 132/200\n",
      "80/80 [==============================] - 0s 673us/step - loss: 0.1130 - accuracy: 0.9490 - val_loss: 0.0894 - val_accuracy: 0.9670\n",
      "Epoch 133/200\n",
      "80/80 [==============================] - 0s 689us/step - loss: 0.1128 - accuracy: 0.9498 - val_loss: 0.0895 - val_accuracy: 0.9660\n",
      "Epoch 134/200\n",
      "80/80 [==============================] - 0s 668us/step - loss: 0.1131 - accuracy: 0.9495 - val_loss: 0.0894 - val_accuracy: 0.9670\n",
      "Epoch 135/200\n",
      "80/80 [==============================] - 0s 639us/step - loss: 0.1130 - accuracy: 0.9488 - val_loss: 0.0895 - val_accuracy: 0.9660\n",
      "Epoch 136/200\n",
      "80/80 [==============================] - 0s 616us/step - loss: 0.1128 - accuracy: 0.9500 - val_loss: 0.0901 - val_accuracy: 0.9650\n",
      "Epoch 137/200\n",
      "80/80 [==============================] - 0s 606us/step - loss: 0.1131 - accuracy: 0.9505 - val_loss: 0.0896 - val_accuracy: 0.9670\n",
      "Epoch 138/200\n",
      "80/80 [==============================] - 0s 608us/step - loss: 0.1130 - accuracy: 0.9488 - val_loss: 0.0911 - val_accuracy: 0.9670\n",
      "Epoch 139/200\n",
      "80/80 [==============================] - 0s 633us/step - loss: 0.1134 - accuracy: 0.9492 - val_loss: 0.0895 - val_accuracy: 0.9670\n",
      "Epoch 140/200\n",
      "80/80 [==============================] - 0s 662us/step - loss: 0.1130 - accuracy: 0.9495 - val_loss: 0.0895 - val_accuracy: 0.9670\n",
      "Epoch 141/200\n",
      "80/80 [==============================] - 0s 620us/step - loss: 0.1131 - accuracy: 0.9485 - val_loss: 0.0891 - val_accuracy: 0.9670\n",
      "Epoch 142/200\n",
      "80/80 [==============================] - 0s 601us/step - loss: 0.1130 - accuracy: 0.9490 - val_loss: 0.0893 - val_accuracy: 0.9680\n",
      "Epoch 143/200\n",
      "80/80 [==============================] - 0s 598us/step - loss: 0.1131 - accuracy: 0.9490 - val_loss: 0.0892 - val_accuracy: 0.9670\n",
      "Epoch 144/200\n",
      "80/80 [==============================] - 0s 603us/step - loss: 0.1130 - accuracy: 0.9498 - val_loss: 0.0895 - val_accuracy: 0.9670\n",
      "Epoch 145/200\n",
      "80/80 [==============================] - 0s 623us/step - loss: 0.1128 - accuracy: 0.9495 - val_loss: 0.0892 - val_accuracy: 0.9670\n",
      "Epoch 146/200\n",
      "80/80 [==============================] - 0s 618us/step - loss: 0.1127 - accuracy: 0.9490 - val_loss: 0.0896 - val_accuracy: 0.9670\n",
      "Epoch 147/200\n",
      "80/80 [==============================] - 0s 617us/step - loss: 0.1127 - accuracy: 0.9500 - val_loss: 0.0895 - val_accuracy: 0.9660\n",
      "Epoch 148/200\n",
      "80/80 [==============================] - 0s 601us/step - loss: 0.1128 - accuracy: 0.9492 - val_loss: 0.0905 - val_accuracy: 0.9660\n",
      "Epoch 149/200\n",
      "80/80 [==============================] - 0s 608us/step - loss: 0.1130 - accuracy: 0.9485 - val_loss: 0.0894 - val_accuracy: 0.9660\n",
      "Epoch 150/200\n",
      "80/80 [==============================] - 0s 607us/step - loss: 0.1130 - accuracy: 0.9507 - val_loss: 0.0893 - val_accuracy: 0.9670\n",
      "Epoch 151/200\n",
      "80/80 [==============================] - 0s 601us/step - loss: 0.1129 - accuracy: 0.9485 - val_loss: 0.0900 - val_accuracy: 0.9650\n",
      "Epoch 152/200\n",
      "80/80 [==============================] - 0s 622us/step - loss: 0.1127 - accuracy: 0.9503 - val_loss: 0.0892 - val_accuracy: 0.9670\n",
      "Epoch 153/200\n",
      "80/80 [==============================] - 0s 608us/step - loss: 0.1126 - accuracy: 0.9485 - val_loss: 0.0899 - val_accuracy: 0.9660\n",
      "Epoch 154/200\n",
      "80/80 [==============================] - 0s 610us/step - loss: 0.1130 - accuracy: 0.9503 - val_loss: 0.0894 - val_accuracy: 0.9670\n",
      "Epoch 155/200\n",
      "80/80 [==============================] - 0s 625us/step - loss: 0.1132 - accuracy: 0.9490 - val_loss: 0.0900 - val_accuracy: 0.9650\n",
      "Epoch 156/200\n",
      "80/80 [==============================] - 0s 607us/step - loss: 0.1129 - accuracy: 0.9498 - val_loss: 0.0895 - val_accuracy: 0.9660\n",
      "Epoch 157/200\n",
      "80/80 [==============================] - 0s 607us/step - loss: 0.1128 - accuracy: 0.9488 - val_loss: 0.0906 - val_accuracy: 0.9650\n",
      "Epoch 158/200\n",
      "80/80 [==============================] - 0s 634us/step - loss: 0.1131 - accuracy: 0.9477 - val_loss: 0.0900 - val_accuracy: 0.9650\n",
      "Epoch 159/200\n",
      "80/80 [==============================] - 0s 613us/step - loss: 0.1128 - accuracy: 0.9490 - val_loss: 0.0893 - val_accuracy: 0.9680\n",
      "Epoch 160/200\n",
      "80/80 [==============================] - 0s 637us/step - loss: 0.1128 - accuracy: 0.9492 - val_loss: 0.0897 - val_accuracy: 0.9660\n",
      "Epoch 161/200\n",
      "80/80 [==============================] - 0s 604us/step - loss: 0.1129 - accuracy: 0.9488 - val_loss: 0.0899 - val_accuracy: 0.9660\n",
      "Epoch 162/200\n",
      "80/80 [==============================] - 0s 614us/step - loss: 0.1127 - accuracy: 0.9495 - val_loss: 0.0898 - val_accuracy: 0.9670\n",
      "Epoch 163/200\n",
      "80/80 [==============================] - 0s 603us/step - loss: 0.1127 - accuracy: 0.9503 - val_loss: 0.0910 - val_accuracy: 0.9670\n",
      "Epoch 164/200\n",
      "80/80 [==============================] - 0s 633us/step - loss: 0.1135 - accuracy: 0.9500 - val_loss: 0.0904 - val_accuracy: 0.9660\n",
      "Epoch 165/200\n",
      "80/80 [==============================] - 0s 610us/step - loss: 0.1133 - accuracy: 0.9490 - val_loss: 0.0895 - val_accuracy: 0.9680\n",
      "Epoch 166/200\n",
      "80/80 [==============================] - 0s 616us/step - loss: 0.1131 - accuracy: 0.9503 - val_loss: 0.0891 - val_accuracy: 0.9670\n",
      "Epoch 167/200\n",
      "80/80 [==============================] - 0s 613us/step - loss: 0.1130 - accuracy: 0.9498 - val_loss: 0.0899 - val_accuracy: 0.9670\n",
      "Epoch 168/200\n",
      "80/80 [==============================] - 0s 611us/step - loss: 0.1129 - accuracy: 0.9498 - val_loss: 0.0904 - val_accuracy: 0.9650\n",
      "Epoch 169/200\n",
      "80/80 [==============================] - 0s 630us/step - loss: 0.1132 - accuracy: 0.9498 - val_loss: 0.0907 - val_accuracy: 0.9670\n",
      "Epoch 170/200\n",
      "80/80 [==============================] - 0s 647us/step - loss: 0.1130 - accuracy: 0.9482 - val_loss: 0.0897 - val_accuracy: 0.9660\n",
      "Epoch 171/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 661us/step - loss: 0.1129 - accuracy: 0.9490 - val_loss: 0.0895 - val_accuracy: 0.9670\n",
      "Epoch 172/200\n",
      "80/80 [==============================] - 0s 609us/step - loss: 0.1134 - accuracy: 0.9505 - val_loss: 0.0898 - val_accuracy: 0.9660\n",
      "Epoch 173/200\n",
      "80/80 [==============================] - 0s 622us/step - loss: 0.1134 - accuracy: 0.9503 - val_loss: 0.0892 - val_accuracy: 0.9670\n",
      "Epoch 174/200\n",
      "80/80 [==============================] - 0s 611us/step - loss: 0.1128 - accuracy: 0.9495 - val_loss: 0.0893 - val_accuracy: 0.9670\n",
      "Epoch 175/200\n",
      "80/80 [==============================] - 0s 638us/step - loss: 0.1128 - accuracy: 0.9498 - val_loss: 0.0899 - val_accuracy: 0.9650\n",
      "Epoch 176/200\n",
      "80/80 [==============================] - 0s 645us/step - loss: 0.1127 - accuracy: 0.9490 - val_loss: 0.0895 - val_accuracy: 0.9670\n",
      "Epoch 177/200\n",
      "80/80 [==============================] - 0s 601us/step - loss: 0.1134 - accuracy: 0.9490 - val_loss: 0.0894 - val_accuracy: 0.9670\n",
      "Epoch 178/200\n",
      "80/80 [==============================] - 0s 609us/step - loss: 0.1126 - accuracy: 0.9505 - val_loss: 0.0899 - val_accuracy: 0.9650\n",
      "Epoch 179/200\n",
      "80/80 [==============================] - 0s 613us/step - loss: 0.1128 - accuracy: 0.9498 - val_loss: 0.0897 - val_accuracy: 0.9670\n",
      "Epoch 180/200\n",
      "80/80 [==============================] - 0s 618us/step - loss: 0.1128 - accuracy: 0.9482 - val_loss: 0.0907 - val_accuracy: 0.9660\n",
      "Epoch 181/200\n",
      "80/80 [==============================] - 0s 687us/step - loss: 0.1127 - accuracy: 0.9495 - val_loss: 0.0893 - val_accuracy: 0.9660\n",
      "Epoch 182/200\n",
      "80/80 [==============================] - 0s 667us/step - loss: 0.1129 - accuracy: 0.9492 - val_loss: 0.0897 - val_accuracy: 0.9660\n",
      "Epoch 183/200\n",
      "80/80 [==============================] - 0s 623us/step - loss: 0.1128 - accuracy: 0.9480 - val_loss: 0.0908 - val_accuracy: 0.9670\n",
      "Epoch 184/200\n",
      "80/80 [==============================] - 0s 619us/step - loss: 0.1128 - accuracy: 0.9503 - val_loss: 0.0893 - val_accuracy: 0.9680\n",
      "Epoch 185/200\n",
      "80/80 [==============================] - 0s 602us/step - loss: 0.1131 - accuracy: 0.9490 - val_loss: 0.0901 - val_accuracy: 0.9660\n",
      "Epoch 186/200\n",
      "80/80 [==============================] - 0s 628us/step - loss: 0.1130 - accuracy: 0.9495 - val_loss: 0.0895 - val_accuracy: 0.9670\n",
      "Epoch 187/200\n",
      "80/80 [==============================] - 0s 600us/step - loss: 0.1130 - accuracy: 0.9485 - val_loss: 0.0893 - val_accuracy: 0.9670\n",
      "Epoch 188/200\n",
      "80/80 [==============================] - 0s 655us/step - loss: 0.1129 - accuracy: 0.9503 - val_loss: 0.0893 - val_accuracy: 0.9660\n",
      "Epoch 189/200\n",
      "80/80 [==============================] - 0s 621us/step - loss: 0.1132 - accuracy: 0.9492 - val_loss: 0.0893 - val_accuracy: 0.9670\n",
      "Epoch 190/200\n",
      "80/80 [==============================] - 0s 655us/step - loss: 0.1133 - accuracy: 0.9498 - val_loss: 0.0894 - val_accuracy: 0.9660\n",
      "Epoch 191/200\n",
      "80/80 [==============================] - 0s 641us/step - loss: 0.1133 - accuracy: 0.9495 - val_loss: 0.0900 - val_accuracy: 0.9660\n",
      "Epoch 192/200\n",
      "80/80 [==============================] - 0s 633us/step - loss: 0.1129 - accuracy: 0.9482 - val_loss: 0.0895 - val_accuracy: 0.9670\n",
      "Epoch 193/200\n",
      "80/80 [==============================] - 0s 627us/step - loss: 0.1127 - accuracy: 0.9495 - val_loss: 0.0904 - val_accuracy: 0.9660\n",
      "Epoch 194/200\n",
      "80/80 [==============================] - 0s 633us/step - loss: 0.1127 - accuracy: 0.9492 - val_loss: 0.0895 - val_accuracy: 0.9670\n",
      "Epoch 195/200\n",
      "80/80 [==============================] - 0s 629us/step - loss: 0.1129 - accuracy: 0.9503 - val_loss: 0.0894 - val_accuracy: 0.9670\n",
      "Epoch 196/200\n",
      "80/80 [==============================] - 0s 661us/step - loss: 0.1128 - accuracy: 0.9492 - val_loss: 0.0898 - val_accuracy: 0.9650\n",
      "Epoch 197/200\n",
      "80/80 [==============================] - 0s 604us/step - loss: 0.1127 - accuracy: 0.9485 - val_loss: 0.0892 - val_accuracy: 0.9670\n",
      "Epoch 198/200\n",
      "80/80 [==============================] - 0s 611us/step - loss: 0.1129 - accuracy: 0.9492 - val_loss: 0.0894 - val_accuracy: 0.9670\n",
      "Epoch 199/200\n",
      "80/80 [==============================] - 0s 644us/step - loss: 0.1135 - accuracy: 0.9492 - val_loss: 0.0900 - val_accuracy: 0.9660\n",
      "Epoch 200/200\n",
      "80/80 [==============================] - 0s 640us/step - loss: 0.1128 - accuracy: 0.9492 - val_loss: 0.0892 - val_accuracy: 0.9670\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x158c185e0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y, epochs = 200, validation_split = 0.2, batch_size = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[3.721053 ],\n",
       "        [1.1808088],\n",
       "        [4.3950257]], dtype=float32),\n",
       " array([-4.7932577], dtype=float32)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights() # almost the same than our previous logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin(model.history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x159ddaaf0>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " plt.plot(model.history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x159f4f3d0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " plt.plot(model.history.history['loss'][20:100]) # If we look closer we see fluctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function is not decreasing monotically. There are some oscillations. This fluctuation comes from the mini-batch approach. In our gradient descent we move to the wrong side (left or right), then we correct this movement on the next iteration. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x159f22f10>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Dense(1, input_shape = (3,), use_bias = True, activation = 'sigmoid'))       \n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(0.01), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(x,y, epochs = 186, batch_size = 50, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[3.8650124],\n",
       "        [1.1829616],\n",
       "        [4.5494337]], dtype=float32),\n",
       " array([-4.927863], dtype=float32)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights() # the coefficients we get are the same than our pervious coefficients!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing NN for image classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fashion MNIST classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "fashion_mnist = keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 3us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 6s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_labels) # 10 types of objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(train_images[10])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression model with 10 possible outcomes - multinomial \n",
    "\n",
    "\n",
    "model = keras.Sequential([keras.layers.Flatten(input_shape = (28,28)), keras.layers.Dense(128, activation = 'relu'), keras.layers.Dense(10, activation = 'softmax')])\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4800/4800 [==============================] - 3s 711us/step - loss: 2.2801 - accuracy: 0.6654 - val_loss: 0.8889 - val_accuracy: 0.7119\n",
      "Epoch 2/10\n",
      "4800/4800 [==============================] - 3s 621us/step - loss: 0.8081 - accuracy: 0.7060 - val_loss: 0.8031 - val_accuracy: 0.7138\n",
      "Epoch 3/10\n",
      "4800/4800 [==============================] - 3s 608us/step - loss: 0.7482 - accuracy: 0.7268 - val_loss: 0.7549 - val_accuracy: 0.6999\n",
      "Epoch 4/10\n",
      "4800/4800 [==============================] - 3s 622us/step - loss: 0.7269 - accuracy: 0.7338 - val_loss: 0.7734 - val_accuracy: 0.7274\n",
      "Epoch 5/10\n",
      "4800/4800 [==============================] - 3s 640us/step - loss: 0.7171 - accuracy: 0.7380 - val_loss: 0.6945 - val_accuracy: 0.7577\n",
      "Epoch 6/10\n",
      "4800/4800 [==============================] - 3s 689us/step - loss: 0.7111 - accuracy: 0.7410 - val_loss: 0.7690 - val_accuracy: 0.7340\n",
      "Epoch 7/10\n",
      "4800/4800 [==============================] - 3s 667us/step - loss: 0.7092 - accuracy: 0.7449 - val_loss: 0.8107 - val_accuracy: 0.7357\n",
      "Epoch 8/10\n",
      "4800/4800 [==============================] - 3s 653us/step - loss: 0.6958 - accuracy: 0.7484 - val_loss: 0.7800 - val_accuracy: 0.7281\n",
      "Epoch 9/10\n",
      "4800/4800 [==============================] - 3s 669us/step - loss: 0.6940 - accuracy: 0.7496 - val_loss: 0.6901 - val_accuracy: 0.7699\n",
      "Epoch 10/10\n",
      "4800/4800 [==============================] - 3s 683us/step - loss: 0.6924 - accuracy: 0.7513 - val_loss: 0.7232 - val_accuracy: 0.7563\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15a320490>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs = 10, validation_split = 0.2, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin(model.history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "4800/4800 [==============================] - 3s 700us/step - loss: 2.4554 - accuracy: 0.6489 - val_loss: 0.7924 - val_accuracy: 0.6974\n",
      "Epoch 2/7\n",
      "4800/4800 [==============================] - 3s 636us/step - loss: 0.7560 - accuracy: 0.7163 - val_loss: 0.8906 - val_accuracy: 0.6594\n",
      "Epoch 3/7\n",
      "4800/4800 [==============================] - 3s 596us/step - loss: 0.7578 - accuracy: 0.7221 - val_loss: 0.8277 - val_accuracy: 0.7197\n",
      "Epoch 4/7\n",
      "4800/4800 [==============================] - 3s 590us/step - loss: 0.6978 - accuracy: 0.7458 - val_loss: 0.7801 - val_accuracy: 0.7342\n",
      "Epoch 5/7\n",
      "4800/4800 [==============================] - 3s 590us/step - loss: 0.6821 - accuracy: 0.7507 - val_loss: 0.7685 - val_accuracy: 0.7486\n",
      "Epoch 6/7\n",
      "4800/4800 [==============================] - 3s 604us/step - loss: 0.6645 - accuracy: 0.7558 - val_loss: 0.6703 - val_accuracy: 0.7680\n",
      "Epoch 7/7\n",
      "4800/4800 [==============================] - 3s 667us/step - loss: 0.6715 - accuracy: 0.7562 - val_loss: 0.6871 - val_accuracy: 0.7678\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15a552d30>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([keras.layers.Flatten(input_shape = (28,28)), keras.layers.Dense(128, activation = 'relu'), keras.layers.Dense(10, activation = 'softmax')])\n",
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs = 7, validation_split = 0.2, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATEAAAD4CAYAAACE9dGgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAY00lEQVR4nO3df4xd5Z3f8fdnxmMP2Cb+lXgHY0LKOqy8u1mTWoSGbEREN0tQJUO7QkEtcbd0TSujghRVYVGlUEVIqApks+ouqikoTguhbIHirrwQr5c2S7oQDHWMjZvFS2xhY2yMCTY2tmfmfvvHPRPu+M55zpm59869Z/x5oaO593zvOefh2v7Oc57zPc9RRGBmVlV93W6AmVkrnMTMrNKcxMys0pzEzKzSnMTMrNJmTefBZmtODDJ3Og85I9QWpr8zfXw4N3bmw4H0zmfV0vs+k/49F0W/BvsTV78LLozPnj2SjOv1MwUHP/ec4gRn4rRa2cfvfmluvHt0tNRnX95x+tmIuLaV47WqpSQm6Vrgu0A/8J8j4t7U5weZy+d0TSuHrCYV/J0qKHM58Q8/l4zP+VcHc2N7d16Y3LbvE6fS8Z+fl4yPzE23PRbkJ9gYTmfAT37ynWR8zpf3JuPnohdja8v7ePfoKD959uJSn+0fen1Jywds0ZRPJyX1A38CfAVYCdwkaWW7GmZm3RFAreR/RSQtl/ScpNck7ZJ0e7b+bkkHJG3PlusatvlDSXsk/UzS7xYdo5We2BXAnoh4IzvwY8Aa4LUW9mlmXRYEw1HudLKEEeDrEfGKpPnAy5K2ZLHvRMS3Gz+cdYS+Cvw6cCHwl5I+HZHfoFYG9pcBbza835+tG0fSOknbJG0b5nQLhzOz6dKunlhEHIyIV7LXx4HdTJAnGqwBHouI0xHxc2AP9Q5Tro5fnYyIDRGxOiJWDzCn04czsxYFwWiUW4AlY52UbFmXt19JlwCXAy9mq26TtEPSw5IWZutKdY4atZLEDgDLG95flK0zs4qrEaUW4MhYJyVbNky0P0nzgCeAOyLiGPAAcCmwCjgI3DfVtraSxF4CVkj6lKTZ1M9jN7WwPzPrAQGMEqWWMiQNUE9gj0TEkwARcSgiRiOiBjzIR6eMk+4cTXlgPyJGJN0GPEu9xOLhiNg11f3NaCr4XVEwiPqZb/w0Gf/TZS/kB1u8Xvx3V32QjA/1z07Gz+/Ljx8cKdj3rHnJ+Odu/tfJ+IL/8jfJuOWrlUxQRSQJeAjYHRH3N6wfioix2qAbgJ3Z603Ao5Lupz6wvwL4SeoYLdWJRcRmYHMr+zCz3hLAcPum6LoKuBl4VdL2bN1d1EuyVmWH2wvcChARuyQ9Tr3KYQRYn7oyCdNcsW9mvS8mcapYuK+I54GJqr1zOz8RcQ9wT9ljOImZ2XgBoxWaK9VJzMzGqVfsV4eTmJmdRYxOeAbYm5zEzGyc+sC+k5iZVVS9TsxJzBrVWruZ9s6lf5mM7ziT/8f40oeXJLddPvBuMj7Yl67Vevn0x5Lxk7X8W836SM/i8rULjiTjv7gsGWZBOmwJNffEzKyq3BMzs0oLxGiFZq53EjOzJj6dNLPKCsSZ6O92M0pzEjOzcerFrj6dNLMK88C+tdXFBVPSvHM6/9FlK+a8ndx2Nunyj3dr6cfFDSr/aUYAiwfyp9t5dzT9/1XkzDI/sq0TIsRo4bP4eoeTmJk1qbknZmZVVR/Yr05qqE5LzWxaeGDfzCpv1HViZlZVrtg3s8qr+eqkmVVV/QZwJzGbhFmXXFzwie3J6PHaYG6sqGhxttJ1YkV1YCci/VT34cRVrqLf9n83nH6k26Ilx5Nxm5pADPu2IzOrqghc7GpmVSYXu5pZdQXuiZlZxXlg38wqK5AnRTSz6qo/sq06qaE6LTWzaeKH59okvb96qKXtjyXqxH5l1vvJbU/FQEvxojqzPmq5scG+dA3au4nHvQFcujD9uLn0/7nlCc6hin1Je4HjwCgwEhGr29EoM+uuc60n9qWISD/l1MwqI0LnTk/MzGae+sD+uXPbUQA/lBTAf4qIDWd/QNI6YB3AIOe3eDgz67xqzbHfaku/EBGfBb4CrJf0xbM/EBEbImJ1RKweID1Qa2bdVx/YV6mliKTlkp6T9JqkXZJuz9YvkrRF0uvZz4XZekn6Y0l7JO2Q9NmiY7SUxCLiQPbzMPAUcEUr+zOz3jBKX6mlhBHg6xGxEriSemdnJXAnsDUiVgBbs/dQ7xCtyJZ1wANFB5hyEpM0V9L8sdfAl4GdU92fmfWGsYr9dvTEIuJgRLySvT4O7AaWAWuAjdnHNgLXZ6/XAN+PuheABZKSNUitjIktBZ6SNLafRyPimRb2d8468pn075L3ax8m4++M/EpubNmsXyS3XdyX3veKWek5vX56ZnEynnrgRKqGDGBx3+lk/J0P08+tnE26jszyTeJBIUskbWt4v2GisXEASZcAlwMvAksj4mAWept6PoF6gnuzYbP92bqD5JhyEouIN4Dfmur2ZtabImC4VjqJHSlTHyppHvAEcEdEHMs6P9nxIrKLg1PiEgszG6d+Otm+q5OSBqgnsEci4sls9SFJQxFxMDtdPJytPwAsb9j8omxdrupcRzWzaTOa3T9ZtBRRvcv1ELA7Iu5vCG0C1mav1wJPN6z/WnaV8krg/YbTzgm5J2Zm44yVWLTJVcDNwKuStmfr7gLuBR6XdAuwD7gxi20GrgP2ACeB3y86gJOYmZ2lfaeTEfE85HbZrpng8wGsn8wxnMTMrInn2LdJmXt5uhRgONKlCMsG3suNnYjZyW0vGziVjH/zUNNNGOP8u088n4y/Opx/q9mp0XSJxFB/uu373kqXd6xgXzJuE6tfnTx37p00sxnG01ObWeX5dNLMKqvNVyc7zknMzJp4UkQzq6wIMeIkZmZV5tNJM6ssj4nZpP2TT/40GT9eS9/gfyYxH/rKgql0/urDTyTjO/9+ukZt4VvpKcdnD+c/0m1AI8ltz+9L14npvXTcps5JzMwqy3ViZlZ5rhMzs8qKgJHykyJ2nZOYmTXx6aSZVZbHxMys8sJJzMyqzAP7NimXDSanEOdkog4MYDjy/xgvnpWes+u6bTck48vYlYwXGUzUgp2qFdV5pec6q81O17DZ1ER4TMzMKk2M+uqkmVWZx8TMrLJ876SZVVvUx8WqwknMzJr46qSZVVZ4YN/Mqs6nkzYpnx98Kxl/azRdTzXaQtd//p/Nn/K2AO+NnkzGf3P2YG7s5VPpucjgWDp8Xv5cZdaaKl2dLOwzSnpY0mFJOxvWLZK0RdLr2c+FnW2mmU2XiHoSK7P0gjInvt8Drj1r3Z3A1ohYAWzN3pvZDFELlVp6QWESi4gfAUfPWr0G2Ji93ghc395mmVk3RZRbesFUx8SWRsTYDX9vA0vzPihpHbAOYJCiMRAz67ZA1Cp0dbLllkZEUC/yzYtviIjVEbF6gDmtHs7MpkGUXHrBVJPYIUlDANnPw+1rkpl11Qwc2J/IJmBt9not8HR7mmNmPaFCXbHCMTFJPwCuBpZI2g98E7gXeFzSLcA+4MZONnKmGyqY82vfSLoeam7f6Skfe8HTO5Lxohm7bt9/9oXr8b570TO5scG+4YK9p/UfHWhpe8vXK72sMgqTWETclBO6ps1tMbMeEECt1p4kJulh4B8BhyPiN7J1dwN/ALyTfeyuiNicxf4QuAUYBf5NRDxbdIzqXIIws+kRQKjcUux7NNeZAnwnIlZly1gCWwl8Ffj1bJs/lZSe1hgnMTObQLvqxHLqTPOsAR6LiNMR8XNgD3BF0UZOYmbWrPzA/hJJ2xqWdSWPcJukHdltjWO3LS4D3mz4zP5sXZJvADezs0yqfOJIRKye5AEeAL5FPQ1+C7gP+BeT3McvuSdmZs06WGIREYciYjQiasCDfHTKeABY3vDRi7J1Se6JzQDz+/IfbXaydia5be1keiqdItsOXJyMz1me/1esv7CAI23gmH8Hd0RAtOnq5EQkDTXctngDMDZDzibgUUn3AxcCK4CfFO3PSczMJtC2EouJ6kyvlrSKel9uL3ArQETskvQ48BowAqyPiMJJ45zEzKxZm6rxc+pMH0p8/h7gnskcw0nMzJr1yC1FZTiJmdl4Y8WuFeEkZmZNemXCwzKcxMysWQevTrabk5iZNZF7YtZORY9ku0D5U/H81+Ofandzxjn11txkfCBx/+6oa617Uw/NFVaGk5iZnaX0DBU9wUnMzJq5J2ZmldbaHWHTyknMzMZznZiZVZ2vTppZtVUoifkat5lVmntiFXCiln5y+vLZ+XOCbdx3ZXLbebwxpTaNufgv0iPAJ/9x/nxmAxpp6djWOT6dNLPqCnzbkZlVnHtiZlZlPp00s2pzEjOzSnMSM7OqUvh00syqzlcnrZ1mK/3UqlTF8lv7Fie3/XSLdWLn//hnyfjH+s7LjV2QeF5mGbNae2SmJVSpJ1ZYsS/pYUmHJe1sWHe3pAOStmfLdZ1tpplNqw4+Abzdytx29D3g2gnWfyciVmXL5vY2y8y6Jj4aFytaekFhEouIHwFHp6EtZtYrZlhPLM9tknZkp5sL8z4kaZ2kbZK2DZM/F7yZ9Q7Vyi29YKpJ7AHgUmAVcBC4L++DEbEhIlZHxOoB0jcym5lN1pSSWEQciojRiKgBDwJXtLdZZtZVM/10UtJQw9sbgJ15nzWziqnYwH5hnZikHwBXA0sk7Qe+CVwtaRX1XLwXuLVzTZz5njmZPs2+cNb7yfhw4i/TnLcHptKk0uJM/nxhRQY13NKxZ51oaXNL6ZEEVUZhEouImyZY/VAH2mJmvWImJTEzO7eI3rnyWIaTmJmN10PjXWX4QSFm1qxNVydzbltcJGmLpNeznwuz9ZL0x5L2ZDWony3TVCcxM2vWvhKL79F82+KdwNaIWAFszd4DfAVYkS3rqNejFnISM7Mm7SqxyLltcQ2wMXu9Ebi+Yf33o+4FYMFZ5VwT8phYD3j+g08n4/90wYvJ+GBi6qeRX/1wKk0qrXZq6tPpnIqi8o/0bWoj50/50Faks2NiSyPiYPb6bWBp9noZ8GbD5/Zn6w6S4CRmZuPFpK5OLpG0reH9hojYUPpQESG1dhnBSczMmpVPK0ciYvUk935I0lBEHMxOFw9n6w8Ayxs+d1G2LsljYmbWpMO3HW0C1mav1wJPN6z/WnaV8krg/YbTzlzuiZlZszaNieXctngv8LikW4B9wI3ZxzcD1wF7gJPA75c5hpOYmY3Xxhkqcm5bBLhmgs8GsH6yx3ASM7NxRLUq9p3EzKyJk5hNymO70hd31v/23yTjR2v9ubHrLktP9ZZ+4FpnLer/oOAT6Tqyfs923jlOYmZWaU5iZlZZFZvFwknMzJo5iZlZlXlSRDOrNJ9Omll19dDj2MpwEjOzZk5iNhnzf3xeMj74xfR9+sdrs3Nj/37p/05u+1U+n4y36nTkP5ZtUKMFW6frxKo0blMlrtg3s8pTrTpZzEnMzMbzmJiZVZ1PJ82s2pzEzKzK3BMzs2pzEjOzyprc0466zkmsBwz9ryPJ+DvfSP9aPBH5dWL/5/TcKbWpXd4Yzq8T6yfxwMwSwo+56Yiq1YkV/jWQtFzSc5Jek7RL0u3Z+kWStkh6Pfu5sPPNNbNpEVFu6QFlfpeNAF+PiJXAlcB6SSuBO4GtEbEC2Jq9N7MZoMOPbGurwiQWEQcj4pXs9XFgN/VHi68BNmYf2whc36E2mtl0ikksPWBSY2KSLgEuB14EljY82PJtYGnONuuAdQCDnD/lhprZ9JmRA/uS5gFPAHdExDHpo0HZiAhp4s5lRGwANgBcoEU9krvNLKVKSazU9R1JA9QT2CMR8WS2+pCkoSw+BBzuTBPNbFoFlRrYL+yJqd7legjYHRH3N4Q2AWupP5J8LfB0R1p4Dhh97W+T8deHFyfji/tO5MY+3p8fA+j7zK8l47Ud/y8ZL3I88qfTmauRlvYd+U+qsxb1yqB9GWVOJ68CbgZelbQ9W3cX9eT1uKRbgH3AjR1poZlNv5mUxCLiecitSrymvc0xs26rWrGrK/bNbLwIT4poZhVXnRzmJGZmzXw6aWbVFYBPJ82s0qqTw5zEqiBVBwYwmKi3WtSXrsU6dtnHkvF5O5LhQs99sDI39nsX/N/ktjvOnErGXSfWOT6dNLNKa+fVSUl7gePAKDASEaslLQL+G3AJsBe4MSLem8r+Pa2cmY3XmVksvhQRqyJidfa+bVN5OYmZ2Tj1YtcotbSgbVN5OYmZWbNayQWWSNrWsKybYG8B/FDSyw3xUlN5leExMTNrMole1pGGU8Q8X4iIA5I+AWyRNG5WgdRUXmW4J2Zm47V5TCwiDmQ/DwNPAVfQxqm8nMTM7Cz1eyfLLEUkzZU0f+w18GVgJx9N5QUtTuXl08npoIJHkxV03f/ZC7ck41uu+o+5saJSqrc/n27br/5ZwQ4KHDi9YMrb9hf8qp/zXoWKmaqmfRMeLgWeymaCngU8GhHPSHqJNk3l5SRmZuO18eG5EfEG8FsTrH+XNk3l5SRmZs16ZOrpMpzEzKxZdXKYk5iZNVOtOo87chIzs/GCsULWSnASM7NxRMu3FE0rJzEza+YkZuOooKY4RpPhj//5YDI+97fza72OFxQkrv+dHybjz3JBMl7kvP7h3Nho7kO0ysX7T1fnH1rlOImZWWV5TMzMqs5XJ82swsKnk2ZWYYGTmJlVXHXOJp3EzKyZ68TMrNpmUhKTtBz4PvV5gQLYEBHflXQ38AfAO9lH74qIzZ1qaJWpPz2rV9TSdWIXPPpCMv7qt/JruRb3nUxuO9zhhzdu2vObubF/e+WPk9seGk3/QzoxlK6/Sz9R03JFwGh1zifL9MRGgK9HxCvZDI0vS9qSxb4TEd/uXPPMrCtmUk8seyLJwez1cUm7gWWdbpiZdVGFktik5tiXdAlwOfBituo2STskPSxpYc4268Ye5zTM6dZaa2adF0Atyi09oHQSkzQPeAK4IyKOAQ8AlwKrqPfU7ptou4jYEBGrI2L1AHNab7GZdVhA1MotPaDU1UlJA9QT2CMR8SRARBxqiD8I/HlHWmhm0yuo1MB+YU9M9ceUPATsjoj7G9YPNXzsBuqPYTKzmSCi3NIDyvTErgJuBl6VtD1bdxdwk6RV1PP2XuDWDrRvRoiR/Olo2uF//uLy3NgfDW1LbnvRrO3J+F9cd0cyPmfzS8l4f3/+b/Ql/XOT287vS39vpxf3xj+iGalHElQZZa5OPg8TTuzkmjCzGal3ellluGLfzMYLwFPxmFmluSdmZtU18247MrNzSUD0SA1YGU5iZtasR6rxy3ASM7NmHhOzcTr8F+KvHr0iN7byH/xactsF/31eMj5/c3oaoCIf+0H+/r80f01y26Mnzk/GL/zrkSm1yQpE+OqkmVWce2JmVl1BjKYn6uwlTmJmNt7YVDwV4SRmZs0qVGIxqUkRzWzmCyBqUWopQ9K1kn4maY+kO9vdXicxMxsv2jcpoqR+4E+ArwArqc9+s7KdzfXppJk1aePA/hXAnoh4A0DSY8Aa4LV2HUAxjZdSJb0D7GtYtQQ4Mm0NmJxebVuvtgvctqlqZ9s+GREfb2UHkp6h3qYyBoFTDe83RMSGhn39HnBtRPzL7P3NwOci4rZW2thoWntiZ3+5krZFxOrpbENZvdq2Xm0XuG1T1Wtti4hru92GyfCYmJl10gFgecP7i7J1beMkZmad9BKwQtKnJM0GvgpsaucBuj2wv6H4I13Tq23r1XaB2zZVvdy2lkTEiKTbgGeBfuDhiNjVzmNM68C+mVm7+XTSzCrNSczMKq0rSazTtyG0QtJeSa9K2i4p/dDGzrflYUmHJe1sWLdI0hZJr2c/F/ZQ2+6WdCD77rZLuq5LbVsu6TlJr0naJen2bH1Xv7tEu3rie6uqaR8Ty25D+Fvgd4D91K9e3BQRbavgbYWkvcDqiOh6YaSkLwIfAN+PiN/I1v0H4GhE3Jv9AlgYEd/okbbdDXwQEd+e7vac1bYhYCgiXpE0H3gZuB7453Txu0u060Z64Hurqm70xH55G0JEnAHGbkOws0TEj4CjZ61eA2zMXm+k/o9g2uW0rSdExMGIeCV7fRzYDSyjy99dol3Wgm4ksWXAmw3v99Nbf5AB/FDSy5LWdbsxE1gaEQez128DS7vZmAncJmlHdrrZlVPdRpIuAS4HXqSHvruz2gU99r1ViQf2m30hIj5L/a779dlpU0+K+lhAL9XIPABcCqwCDgL3dbMxkuYBTwB3RMSxxlg3v7sJ2tVT31vVdCOJdfw2hFZExIHs52HgKeqnv73kUDa2MjbGcrjL7fmliDgUEaNRf2jhg3Txu5M0QD1RPBIRT2aru/7dTdSuXvreqqgbSazjtyFMlaS52YArkuYCXwZ2preadpuAtdnrtcDTXWzLOGMJInMDXfruJAl4CNgdEfc3hLr63eW1q1e+t6rqSsV+dgn5j/joNoR7pr0RE5D096j3vqB+S9aj3WybpB8AV1OfFuUQ8E3gfwCPAxdTn9boxoiY9gH2nLZdTf2UKIC9wK0NY1DT2bYvAH8NvAqMzdx3F/Xxp659d4l23UQPfG9V5duOzKzSPLBvZpXmJGZmleYkZmaV5iRmZpXmJGZmleYkZmaV5iRmZpX2/wGrWqyg0MeB1wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(test_images[2])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectimageid = 2 # this counts from one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 0.0000e+00 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0, 1.0]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images[selectimageid:(selectimageid+1)], test_labels[selectimageid:(selectimageid+1)], verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=uint8)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[selectimageid:(selectimageid+1)] # Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.2348562e-19, 1.0000000e+00, 0.0000000e+00, 3.1993245e-25,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        4.0109554e-32, 0.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test_images[selectimageid:(selectimageid+1)])\n",
    "\n",
    "# The higher probability is given by label 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(test_images[selectimageid:(selectimageid+1)]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
